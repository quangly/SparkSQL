{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/07 11:47:55 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/quangly/github/Spark SQL/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "json_df2_path = data_path + \"/utilization.json\"\n",
    "df_util = spark.read.format(\"json\").load(json_df2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|server_id|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|      103|                0.56|                0.96|    0.11617507884178278|\n",
      "|      104|                0.51|                0.91|    0.11521679513850511|\n",
      "|      106|                0.22|                0.62|    0.11531539914568226|\n",
      "|      100|                0.27|                0.67|     0.1152264191787964|\n",
      "|      105|                0.29|                0.69|    0.11510721467869486|\n",
      "|      101|                 0.6|                 1.0|    0.11651726263197697|\n",
      "|      102|                0.56|                0.96|    0.11549678751286807|\n",
      "|      112|                0.52|                0.92|    0.11528867845082576|\n",
      "|      113|                0.58|                0.98|    0.11544345150353687|\n",
      "|      110|                0.35|                0.75|    0.11533251724450215|\n",
      "|      107|                0.45|                0.85|    0.11597417369783877|\n",
      "|      111|                0.36|                0.76|    0.11530221569464506|\n",
      "|      108|                0.55|                0.95|    0.11563100171171926|\n",
      "|      109|                0.36|                0.76|    0.11574898623219722|\n",
      "|      119|                0.22|                0.62|    0.11516031929842008|\n",
      "|      116|                 0.3|                 0.7|    0.11506079722349302|\n",
      "|      114|                0.33|                0.73|    0.11510268816097273|\n",
      "|      115|                0.44|                0.84|    0.11569664615014985|\n",
      "|      120|                0.35|                0.75|    0.11586355920838642|\n",
      "|      118|                0.53|                0.93|    0.11474318421515234|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT server_id, min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) \\\n",
    "           FROM utilization \\\n",
    "           GROUP BY server_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_window = \"SELECT event_datetime, server_id, cpu_utilization,  \\\n",
    "         avg(cpu_utilization) OVER (PARTITION BY server_id) avg_server_util \\\n",
    "FROM  \\\n",
    "      utilization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "|03/05/2019 08:06:31|      110|           0.68|0.5537749999999892|\n",
      "|03/05/2019 08:11:31|      110|           0.58|0.5537749999999892|\n",
      "|03/05/2019 08:16:31|      110|           0.55|0.5537749999999892|\n",
      "|03/05/2019 08:21:31|      110|           0.63|0.5537749999999892|\n",
      "|03/05/2019 08:26:31|      110|           0.63|0.5537749999999892|\n",
      "|03/05/2019 08:31:31|      110|           0.71|0.5537749999999892|\n",
      "|03/05/2019 08:36:31|      110|           0.67|0.5537749999999892|\n",
      "|03/05/2019 08:41:31|      110|           0.55|0.5537749999999892|\n",
      "|03/05/2019 08:46:31|      110|           0.37|0.5537749999999892|\n",
      "|03/05/2019 08:51:31|      110|            0.7|0.5537749999999892|\n",
      "|03/05/2019 08:56:31|      110|           0.67|0.5537749999999892|\n",
      "|03/05/2019 09:01:31|      110|           0.56|0.5537749999999892|\n",
      "|03/05/2019 09:06:31|      110|           0.37|0.5537749999999892|\n",
      "|03/05/2019 09:11:31|      110|            0.6|0.5537749999999892|\n",
      "|03/05/2019 09:16:31|      110|           0.45|0.5537749999999892|\n",
      "|03/05/2019 09:21:31|      110|           0.65|0.5537749999999892|\n",
      "|03/05/2019 09:26:31|      110|           0.45|0.5537749999999892|\n",
      "|03/05/2019 09:31:31|      110|           0.67|0.5537749999999892|\n",
      "|03/05/2019 09:36:31|      110|            0.5|0.5537749999999892|\n",
      "|03/05/2019 09:41:31|      110|           0.53|0.5537749999999892|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql_window).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes want to compare a value such as current cpu of a server with average of that server. not entire population\n",
    "# windowing function written with PARTITION BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_window2 = \"SELECT event_datetime, server_id, cpu_utilization,  \\\n",
    "         avg(cpu_utilization) OVER (PARTITION BY server_id) avg_server_util, \\\n",
    "         cpu_utilization - avg(cpu_utilization) OVER (PARTITION BY server_id) delta_server_util \\\n",
    "         FROM utilization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|   delta_server_util|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|03/05/2019 08:06:31|      110|           0.68|0.5537749999999892|  0.1262250000000108|\n",
      "|03/05/2019 08:11:31|      110|           0.58|0.5537749999999892|0.026225000000010712|\n",
      "|03/05/2019 08:16:31|      110|           0.55|0.5537749999999892|-0.00377499999998...|\n",
      "|03/05/2019 08:21:31|      110|           0.63|0.5537749999999892| 0.07622500000001076|\n",
      "|03/05/2019 08:26:31|      110|           0.63|0.5537749999999892| 0.07622500000001076|\n",
      "|03/05/2019 08:31:31|      110|           0.71|0.5537749999999892| 0.15622500000001072|\n",
      "|03/05/2019 08:36:31|      110|           0.67|0.5537749999999892| 0.11622500000001079|\n",
      "|03/05/2019 08:41:31|      110|           0.55|0.5537749999999892|-0.00377499999998...|\n",
      "|03/05/2019 08:46:31|      110|           0.37|0.5537749999999892|-0.18377499999998925|\n",
      "|03/05/2019 08:51:31|      110|            0.7|0.5537749999999892|  0.1462250000000107|\n",
      "|03/05/2019 08:56:31|      110|           0.67|0.5537749999999892| 0.11622500000001079|\n",
      "|03/05/2019 09:01:31|      110|           0.56|0.5537749999999892|0.006225000000010805|\n",
      "|03/05/2019 09:06:31|      110|           0.37|0.5537749999999892|-0.18377499999998925|\n",
      "|03/05/2019 09:11:31|      110|            0.6|0.5537749999999892| 0.04622500000001073|\n",
      "|03/05/2019 09:16:31|      110|           0.45|0.5537749999999892|-0.10377499999998924|\n",
      "|03/05/2019 09:21:31|      110|           0.65|0.5537749999999892| 0.09622500000001077|\n",
      "|03/05/2019 09:26:31|      110|           0.45|0.5537749999999892|-0.10377499999998924|\n",
      "|03/05/2019 09:31:31|      110|           0.67|0.5537749999999892| 0.11622500000001079|\n",
      "|03/05/2019 09:36:31|      110|            0.5|0.5537749999999892|-0.05377499999998925|\n",
      "|03/05/2019 09:41:31|      110|           0.53|0.5537749999999892|-0.02377499999998922|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql_window2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate neighborhood of a row\n",
    "# sliding window - ex. last 3 values and average them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_window3 = \"SELECT event_datetime, server_id, cpu_utilization,  \\\n",
    "                      avg(cpu_utilization) OVER (PARTITION BY server_id ORDER BY event_datetime \\\n",
    "                                    ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) avg_server_util \\\n",
    "                FROM  \\\n",
    "                      utilization\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|    avg_server_util|\n",
      "+-------------------+---------+---------------+-------------------+\n",
      "|03/05/2019 08:06:31|      110|           0.68|               0.63|\n",
      "|03/05/2019 08:11:31|      110|           0.58| 0.6033333333333334|\n",
      "|03/05/2019 08:16:31|      110|           0.55| 0.5866666666666666|\n",
      "|03/05/2019 08:21:31|      110|           0.63| 0.6033333333333334|\n",
      "|03/05/2019 08:26:31|      110|           0.63| 0.6566666666666666|\n",
      "|03/05/2019 08:31:31|      110|           0.71| 0.6699999999999999|\n",
      "|03/05/2019 08:36:31|      110|           0.67| 0.6433333333333333|\n",
      "|03/05/2019 08:41:31|      110|           0.55| 0.5300000000000001|\n",
      "|03/05/2019 08:46:31|      110|           0.37|               0.54|\n",
      "|03/05/2019 08:51:31|      110|            0.7|               0.58|\n",
      "|03/05/2019 08:56:31|      110|           0.67| 0.6433333333333334|\n",
      "|03/05/2019 09:01:31|      110|           0.56| 0.5333333333333333|\n",
      "|03/05/2019 09:06:31|      110|           0.37|               0.51|\n",
      "|03/05/2019 09:11:31|      110|            0.6|0.47333333333333333|\n",
      "|03/05/2019 09:16:31|      110|           0.45| 0.5666666666666668|\n",
      "|03/05/2019 09:21:31|      110|           0.65| 0.5166666666666667|\n",
      "|03/05/2019 09:26:31|      110|           0.45|               0.59|\n",
      "|03/05/2019 09:31:31|      110|           0.67|               0.54|\n",
      "|03/05/2019 09:36:31|      110|            0.5| 0.5666666666666667|\n",
      "|03/05/2019 09:41:31|      110|           0.53| 0.5133333333333333|\n",
      "+-------------------+---------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql_window3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.68+0.58)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6033333333333334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.68+0.58+0.55)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
