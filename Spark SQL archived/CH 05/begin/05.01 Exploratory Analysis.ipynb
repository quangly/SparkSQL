{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/quangly/github/Spark SQL/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "json_df2_path = data_path + \"/utilization.json\"\n",
    "df_util = spark.read.format(\"json\").load(json_df2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe() produces another df with summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "|summary|    cpu_utilization|     event_datetime|        free_memory|         server_id|     session_count|\n",
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "|  count|             500000|             500000|             500000|            500000|            500000|\n",
      "|   mean| 0.6205177399999957|               NULL|0.37912809999999864|             124.5|          69.59616|\n",
      "| stddev|0.15875173872912945|               NULL|0.15830931278376276|14.430884120553191|14.850676696352851|\n",
      "|    min|               0.22|03/05/2019 08:06:14|                0.0|               100|                32|\n",
      "|    max|                1.0|04/09/2019 01:22:46|               0.78|               149|               105|\n",
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_util.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|    cpu_utilization|        free_memory|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|             500000|             500000|\n",
      "|   mean| 0.6205177399999957|0.37912809999999864|\n",
      "| stddev|0.15875173872912945|0.15830931278376276|\n",
      "|    min|               0.22|                0.0|\n",
      "|    max|                1.0|               0.78|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.describe('cpu_utilization','free_memory').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation\n",
    "# no correlation : 0\n",
    "# if one value goes up other value always go up: 1\n",
    "# if one value goes up other value goes down: negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.47047715730807554"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.stat.corr('cpu_utilization','free_memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5008320848876574"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.stat.corr('session_count','free_memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqItems - what are freq occuring items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+\n",
      "| server_id_freqItems|session_count_freqItems|\n",
      "+--------------------+-----------------------+\n",
      "|[137, 146, 101, 1...|   [92, 101, 83, 104...|\n",
      "+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.stat.freqItems(('server_id','session_count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# withReplacement = False - as you choose, something out of population, do you want to put it back into population which could create dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25107"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util_sample = df_util.sample(fraction=0.05, withReplacement=False)\n",
    "df_util_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------------+\n",
      "|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "|                0.22|                 1.0|    0.15875173872912945|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) FROM utilization').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|server_id|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|      103|                0.56|                0.96|    0.11617507884178278|\n",
      "|      104|                0.51|                0.91|    0.11521679513850511|\n",
      "|      106|                0.22|                0.62|    0.11531539914568226|\n",
      "|      100|                0.27|                0.67|     0.1152264191787964|\n",
      "|      105|                0.29|                0.69|    0.11510721467869486|\n",
      "|      101|                 0.6|                 1.0|    0.11651726263197697|\n",
      "|      102|                0.56|                0.96|    0.11549678751286807|\n",
      "|      112|                0.52|                0.92|    0.11528867845082576|\n",
      "|      113|                0.58|                0.98|    0.11544345150353687|\n",
      "|      110|                0.35|                0.75|    0.11533251724450215|\n",
      "|      107|                0.45|                0.85|    0.11597417369783877|\n",
      "|      111|                0.36|                0.76|    0.11530221569464506|\n",
      "|      108|                0.55|                0.95|    0.11563100171171926|\n",
      "|      109|                0.36|                0.76|    0.11574898623219722|\n",
      "|      119|                0.22|                0.62|    0.11516031929842008|\n",
      "|      116|                 0.3|                 0.7|    0.11506079722349302|\n",
      "|      114|                0.33|                0.73|    0.11510268816097273|\n",
      "|      115|                0.44|                0.84|    0.11569664615014985|\n",
      "|      120|                0.35|                0.75|    0.11586355920838642|\n",
      "|      118|                0.53|                0.93|    0.11474318421515234|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT server_id, min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) \\\n",
    "           FROM utilization \\\n",
    "           GROUP BY server_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buckets or histograms in ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|server_id|bucket|\n",
      "+---------+------+\n",
      "|      100|     5|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     5|\n",
      "|      100|     3|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     5|\n",
      "|      100|     3|\n",
      "|      100|     6|\n",
      "|      100|     6|\n",
      "|      100|     5|\n",
      "|      100|     2|\n",
      "|      100|     4|\n",
      "|      100|     4|\n",
      "|      100|     6|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT server_id, FLOOR(cpu_utilization*100/10) bucket FROM utilization').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|count(1)|bucket|\n",
      "+--------+------+\n",
      "|    8186|     2|\n",
      "|   37029|     3|\n",
      "|   68046|     4|\n",
      "|  104910|     5|\n",
      "|  116725|     6|\n",
      "|   88242|     7|\n",
      "|   56598|     8|\n",
      "|   20207|     9|\n",
      "|      57|    10|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT count(*), FLOOR(cpu_utilization*100/10) bucket FROM utilization GROUP BY bucket ORDER BY bucket').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
